{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:35:57.116853Z",
     "start_time": "2025-08-28T11:35:57.073211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import ssl\n",
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "from gpt_download3 import download_and_load_gpt2\n",
    "from Functions import load_weights_into_gpt, calc_loss_batch, calc_loss_loader,text_to_token_ids, token_ids_to_text, evaluate_model,plot_losses, generate"
   ],
   "id": "fd4451cf9fb1b2bb",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'query_model' from 'Functions' (C:\\Users\\DELL\\PycharmProjects\\LLM\\Functions.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mgpt_download3\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m download_and_load_gpt2\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mFunctions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m load_weights_into_gpt, calc_loss_batch, calc_loss_loader,text_to_token_ids, token_ids_to_text, evaluate_model,plot_losses, generate, query_model\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'query_model' from 'Functions' (C:\\Users\\DELL\\PycharmProjects\\LLM\\Functions.py)"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:08.050425Z",
     "start_time": "2025-08-28T11:05:08.030281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def download_and_load_file(file_path, url):\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n"
   ],
   "id": "95e6a3ad37fb7666",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:08.112665Z",
     "start_time": "2025-08-28T11:05:08.064976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ],
   "id": "dd084f08b2e954af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:08.709514Z",
     "start_time": "2025-08-28T11:05:08.696155Z"
    }
   },
   "cell_type": "code",
   "source": "data[0]",
   "id": "169d0be2f9de2b9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.',\n",
       " 'input': 'freind --> friend',\n",
       " 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Converting into Alpaca Format",
   "id": "b5ae8bc6d46953ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:08.771152Z",
     "start_time": "2025-08-28T11:05:08.752404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ],
   "id": "d74b9460d3edd713",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Splitting Data into Train - Test - Validation",
   "id": "a180e2231453afda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:08.802524Z",
     "start_time": "2025-08-28T11:05:08.787653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dt = data[:int(len(data) * 0.85)]\n",
    "test_dt  = data[int(len(data) * 0.1):]\n",
    "Val_dt = data[int(len(data) * 0.05):]"
   ],
   "id": "19c3dcda3c2c4e1f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:08.832599Z",
     "start_time": "2025-08-28T11:05:08.819413Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Training set: {len(train_dt)}\\nTest set: {len(test_dt)}\\nVal set: {len(Val_dt)}')",
   "id": "562439a7c868597c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 935\n",
      "Test set: 990\n",
      "Val set: 1045\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:08.863937Z",
     "start_time": "2025-08-28T11:05:08.850984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "id": "ed723b5c2d041ff3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:09.190222Z",
     "start_time": "2025-08-28T11:05:08.881504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ],
   "id": "1aff8a6beb6e0368",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Step 1: Find the longest sequence in the batch\n",
    "    \n",
    "Step 2: Pad and prepare inputs\n",
    "    \n",
    "Step 3: Remove extra padded token added earlier\n",
    "\n",
    "Step 4: Convert list of inputs to tensor and transfer to target device\n",
    "\n",
    "</div>"
   ],
   "id": "69a6df66077be07d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:09.221377Z",
     "start_time": "2025-08-28T11:05:09.209093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ],
   "id": "55626a1e556b201a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:09.626749Z",
     "start_time": "2025-08-28T11:05:09.239508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example\n",
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ],
   "id": "e7f31182f8e354df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]], device='cuda:0')\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "we use the partial function from Python's functools standard library to create a new version of the function with the device argument pre-filled. \n",
    "</div>"
   ],
   "id": "d927f7c5243e74c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:09.657960Z",
     "start_time": "2025-08-28T11:05:09.643920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cust_coll_fn = partial(custom_collate_fn, device=\"cuda\", allowed_max_length=1024)\n",
    "# max length 1024 for not to overwhelm the system. "
   ],
   "id": "452328d114b4af7f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:09.768009Z",
     "start_time": "2025-08-28T11:05:09.675013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_dt , tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=cust_coll_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(Val_dt, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=cust_coll_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_dt, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=cust_coll_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ],
   "id": "d79d2b5469497827",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:09.891704Z",
     "start_time": "2025-08-28T11:05:09.803591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ],
   "id": "8abaedbc4908d8e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading LLM",
   "id": "82aa9678f78c5540"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:09.968961Z",
     "start_time": "2025-08-28T11:05:09.941208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ],
   "id": "8889e989732bb84b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:20.099053Z",
     "start_time": "2025-08-28T11:05:10.051287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from GPT_Model_layers import GPTModel\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ],
   "id": "1701b1e9f1f7800b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:20.161664Z",
     "start_time": "2025-08-28T11:05:20.147150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "\n",
    "    ###Input batch:\n",
    "    ###tensor([[6109, 3626, 6100,  345],\n",
    "    ##[6109, 1110, 6622,  257]])\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)  ### batch, n_tokens, vocab_size\n",
    "\n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ],
   "id": "53b586d9e14315b2",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:20.273937Z",
     "start_time": "2025-08-28T11:05:20.210823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ],
   "id": "3d93d63d67089dee",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:20.337215Z",
     "start_time": "2025-08-28T11:05:20.323610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ],
   "id": "c668d0ebd68b62c0",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:05:21.647798Z",
     "start_time": "2025-08-28T11:05:20.384826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ],
   "id": "61631da1afd5a9f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.167143440246582\n",
      "Validation loss: 4.193932628631591\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:06:09.782356Z",
     "start_time": "2025-08-28T11:05:21.715528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(Val_dt[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ],
   "id": "a20422a2a4d582ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.119, Val loss 3.127\n",
      "Ep 1 (Step 000005): Train loss 1.696, Val loss 1.581\n",
      "Ep 1 (Step 000010): Train loss 1.096, Val loss 1.168\n",
      "Ep 1 (Step 000015): Train loss 1.053, Val loss 1.075\n",
      "Ep 1 (Step 000020): Train loss 0.970, Val loss 1.005\n",
      "Ep 1 (Step 000025): Train loss 0.920, Val loss 0.950\n",
      "Ep 1 (Step 000030): Train loss 0.960, Val loss 0.897\n",
      "Ep 1 (Step 000035): Train loss 0.877, Val loss 0.874\n",
      "Ep 1 (Step 000040): Train loss 0.847, Val loss 0.845\n",
      "Ep 1 (Step 000045): Train loss 0.777, Val loss 0.819\n",
      "Ep 1 (Step 000050): Train loss 0.869, Val loss 0.804\n",
      "Ep 1 (Step 000055): Train loss 0.924, Val loss 0.782\n",
      "Ep 1 (Step 000060): Train loss 0.873, Val loss 0.766\n",
      "Ep 1 (Step 000065): Train loss 0.800, Val loss 0.755\n",
      "Ep 1 (Step 000070): Train loss 0.694, Val loss 0.728\n",
      "Ep 1 (Step 000075): Train loss 0.706, Val loss 0.701\n",
      "Ep 1 (Step 000080): Train loss 0.753, Val loss 0.682\n",
      "Ep 1 (Step 000085): Train loss 0.680, Val loss 0.677\n",
      "Ep 1 (Step 000090): Train loss 0.729, Val loss 0.662\n",
      "Ep 1 (Step 000095): Train loss 0.653, Val loss 0.651\n",
      "Ep 1 (Step 000100): Train loss 0.634, Val loss 0.638\n",
      "Ep 1 (Step 000105): Train loss 0.728, Val loss 0.626\n",
      "Ep 1 (Step 000110): Train loss 0.719, Val loss 0.620\n",
      "Ep 1 (Step 000115): Train loss 0.672, Val loss 0.620\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the cube of 4?  ### Response: The cube of 4 is 4.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: The following is a sentence.  ### Response:\n",
      "Training completed in 0.80 minutes.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:06:10.755468Z",
     "start_time": "2025-08-28T11:06:09.848319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "id": "766c861401a86b29",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:15:01.014219Z",
     "start_time": "2025-08-28T11:06:10.836237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_dt), total=len(test_dt)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_dt[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_dt, file, indent=4)  # \"indent\" for pretty-printing"
   ],
   "id": "7327f9f94f6edddb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 990/990 [08:50<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:22:13.557703Z",
     "start_time": "2025-08-28T11:22:13.543422Z"
    }
   },
   "cell_type": "code",
   "source": "test_dt[0]",
   "id": "fd77a7a55635647f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'What is the chemical formula for carbonic acid?',\n",
       " 'input': '',\n",
       " 'output': 'The chemical formula for carbonic acid is H2CO3.',\n",
       " 'model_response': 'The chemical formula for carbonic acid is HCl.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:26:38.029899Z",
     "start_time": "2025-08-28T11:26:34.729666Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(),\"Instruction_model.pt\")",
   "id": "b12a002f3fc31722",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluating using OLLAMA \n",
   "id": "9df6245b50947b67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:30:51.104607Z",
     "start_time": "2025-08-28T11:30:51.087242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ],
   "id": "e51582d8df2cc813",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "\n",
    "Step 1: Create the data payload as a dictionary\n",
    "    \n",
    "Step 2: Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    \n",
    "Step 3: Create a request object, setting the method to POST and adding necessary headers\n",
    "    \n",
    "Step 4: Send the request and capture the response\n",
    "    \n",
    "</div>"
   ],
   "id": "861f7be5893ff0a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T11:42:31.000186Z",
     "start_time": "2025-08-28T11:42:30.984446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(prompt,model=\"llama3\",url=\"http://localhost:11434/api/chat\"):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    # Create a request object, setting the method to POST and adding necessary headers\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # Send the request and capture the response\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        # Read and decode the response\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data"
   ],
   "id": "2ac60ba5bfe7734d",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:17:18.047845Z",
     "start_time": "2025-08-28T12:16:27.660009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ],
   "id": "e348cf58912fb807",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
      "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
      "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and strong bones.\n",
      "\n",
      "In the wild, llamas might also eat:\n",
      "\n",
      "1. Leaves: They'll munch on leaves from trees and shrubs, like willow or cedar.\n",
      "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or birch.\n",
      "3. Mosses: Llamas have been known to graze on mosses and other types of non-woody plants.\n",
      "\n",
      "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:19:28.670536Z",
     "start_time": "2025-08-28T12:19:22.238892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for entry in test_dt[:2]:\n",
    "    prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry['model_response']}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "    score = query_model(prompt, model)\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt, model))\n",
    "    print(\"\\n-------------------------\")"
   ],
   "id": "f30435bf72308bdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The chemical formula for carbonic acid is H2CO3.\n",
      "\n",
      "Model response:\n",
      ">> The chemical formula for carbonic acid is HCl.\n",
      "\n",
      "Score:\n",
      ">> 4\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> A synonym for 'optimistic' is 'hopeful'.\n",
      "\n",
      "Model response:\n",
      ">> A synonym for 'optimistic' is 'optimistic.'\n",
      "\n",
      "Score:\n",
      ">> 20\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c2c85502c280205b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
