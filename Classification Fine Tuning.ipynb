{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:04.502436Z",
     "start_time": "2025-08-26T11:49:54.358057Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tiktoken\n",
    "from gpt_download3 import download_and_load_gpt2\n",
    "import torch.nn as nn\n",
    "from GPT_Model_layers import GPTModel\n",
    "from Functions import generate, load_weights_into_gpt\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:04.544090Z",
     "start_time": "2025-08-26T11:50:04.530605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Downloading Dataset\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Create an unverified SSL context\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ],
   "id": "ebe1c0f86855ff0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:04.586618Z",
     "start_time": "2025-08-26T11:50:04.551695Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv(data_file_path, sep=\"\\t\", names=['Label', \"Text\"])\n",
   "id": "d28a05d3afb23e00",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.033748Z",
     "start_time": "2025-08-26T11:50:05.008025Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "82d7f1b6fcda5779",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.115891Z",
     "start_time": "2025-08-26T11:50:05.105074Z"
    }
   },
   "cell_type": "code",
   "source": "df['Label'].value_counts()",
   "id": "ae26d33f3006584e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.162256Z",
     "start_time": "2025-08-26T11:50:05.149255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ],
   "id": "597b2da53e6f3231",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.234399Z",
     "start_time": "2025-08-26T11:50:05.215245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# labelling\n",
    "balanced_df['Label'] = balanced_df['Label'].map({\"ham\":0, \"spam\":1})"
   ],
   "id": "9961307df67b8eb9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.313164Z",
     "start_time": "2025-08-26T11:50:05.298605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ],
   "id": "3b9da67c5a824f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.408360Z",
     "start_time": "2025-08-26T11:50:05.395861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n"
   ],
   "id": "bf94972a3eaf028f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.437899Z",
     "start_time": "2025-08-26T11:50:05.420703Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'train_df: {len(train_df)}\\nvalidation : {len(validation_df)}\\ntest : {len(test_df)}')",
   "id": "5cbd6fb81de7465e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: 1045\n",
      "validation : 149\n",
      "test : 300\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.480257Z",
     "start_time": "2025-08-26T11:50:05.459009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# saving in csv for Dataloaders\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ],
   "id": "a51c42b308e4c954",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.511046Z",
     "start_time": "2025-08-26T11:50:05.496999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        label_map = {\"ham\": 0, \"spam\": 1}\n",
    "        self.data[\"Label\"] = self.data[\"Label\"].map(label_map)\n",
    "        \n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            \n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ],
   "id": "4ddef4b6ee82a181",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Step 1: Pre-tokenize texts\n",
    "    \n",
    "Step 2: Truncate sequences if they are longer than max_length\n",
    "    \n",
    "Step 3: Pad sequences to the longest sequence\n",
    "\n",
    "</div>"
   ],
   "id": "c1ab8fba27ba7976"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.761906Z",
     "start_time": "2025-08-26T11:50:05.527712Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = tiktoken.get_encoding(\"gpt2\")",
   "id": "8f90e7aa7f48a5a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.818031Z",
     "start_time": "2025-08-26T11:50:05.776792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "id": "59057e325fbf488c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.844390Z",
     "start_time": "2025-08-26T11:50:05.835121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ],
   "id": "4803612f4cabf9e5",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.873050Z",
     "start_time": "2025-08-26T11:50:05.860830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ],
   "id": "cd7edb45f4b8a174",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initialize model with Pretrained weights ",
   "id": "f2caaf1e28112e56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:50:05.902269Z",
     "start_time": "2025-08-26T11:50:05.889363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Model_1 = \"gpt2-small (124M)\"\n",
    "Model_2 = \"gpt2-xl (1558M)\"\n",
    "Input_Prompt = \"Wake Up Early Morning\"\n",
    "\n",
    "BASE_CONFIG_1 = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "BASE_CONFIG_2 = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG_1.update(model_configs[Model_1])\n",
    "BASE_CONFIG_2.update(model_configs[Model_2])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG_1[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG_1['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG_1['context_length']}`\"\n",
    ")\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG_2[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG_2['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG_2['context_length']}`\"\n",
    ")\n"
   ],
   "id": "fc7383415496798c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:53:11.645329Z",
     "start_time": "2025-08-26T11:50:05.918760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_size_1 = \"124M\"\n",
    "model_size_2 = \"1558M\"\n",
    "\n",
    "settings_1, params_1 = download_and_load_gpt2(model_size= model_size_1, models_dir= \"gpt2\")\n",
    "settings_2, params_2 = download_and_load_gpt2(model_size= model_size_2, models_dir= \"gpt2\")\n",
    "\n",
    "model_1 = GPTModel(BASE_CONFIG_1)\n",
    "load_weights_into_gpt(model_1, params_1)\n",
    "model_1.eval();\n",
    "\n",
    "model_2 = GPTModel(BASE_CONFIG_2)\n",
    "load_weights_into_gpt(model_2, params_2)\n",
    "model_2.eval();"
   ],
   "id": "d9c3fbf570d7bf05",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\1558M\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\1558M\\encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\1558M\\hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\1558M\\model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\1558M\\model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\1558M\\model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\1558M\\vocab.bpe\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:53:14.613858Z",
     "start_time": "2025-08-26T11:53:14.563809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ],
   "id": "55dbd238a632f2ff",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:54:49.751514Z",
     "start_time": "2025-08-26T11:53:14.717381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"Going School is\"\n",
    "\n",
    "token_ids_1 = generate(\n",
    "    model = model_1,\n",
    "    idx = text_to_token_ids(text, tokenizer),\n",
    "    max_new_tokens = 20,\n",
    "    context_size = BASE_CONFIG_1['context_length'],\n",
    ")\n",
    "print(token_ids_to_text(token_ids_1, tokenizer))\n",
    "\n",
    "token_ids_2 = generate(\n",
    "    model = model_2,\n",
    "    idx = text_to_token_ids(text, tokenizer),\n",
    "    max_new_tokens = 20,\n",
    "    context_size = BASE_CONFIG_2['context_length'],\n",
    ")\n",
    "print(token_ids_to_text(token_ids_2, tokenizer))"
   ],
   "id": "c7c9607f562642a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going School is a great way to get started.\n",
      "\n",
      "I'm not sure if you've heard of it,\n",
      "Going School is a free, online, self-paced, online course that will help you learn how to become a\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:54:53.112476Z",
     "start_time": "2025-08-26T11:54:53.090680Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'{model_1}\\n --------\\n{model_2}')",
   "id": "530d1fbddf0e8a3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n",
      " --------\n",
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 1600)\n",
      "  (pos_emb): Embedding(1024, 1600)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (12): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (13): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (14): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (15): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (16): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (17): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (18): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (19): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (20): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (21): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (22): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (23): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (24): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (25): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (26): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (27): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (28): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (29): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (30): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (31): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (32): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (33): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (34): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (35): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (36): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (37): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (38): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (39): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (40): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (41): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (42): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (43): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (44): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (45): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (46): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (47): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:54:53.328201Z",
     "start_time": "2025-08-26T11:54:53.190722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for params_1 in model_1.parameters():\n",
    "    params_1.requires_grad = False\n",
    "    \n",
    "for params_2 in model_2.parameters():\n",
    "    params_2.requires_grad = False"
   ],
   "id": "2bf862c37afa8001",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Then, we replace the output layer (model.out_head), which\n",
    "originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary):\n",
    "</div>"
   ],
   "id": "c8d1229490501cde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:54:53.454389Z",
     "start_time": "2025-08-26T11:54:53.388723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "\n",
    "model_1.out_head = torch.nn.Linear(in_features=BASE_CONFIG_1[\"emb_dim\"], out_features=num_classes)\n",
    "\n",
    "model_2.out_head = torch.nn.Linear(in_features=BASE_CONFIG_2[\"emb_dim\"], out_features=num_classes)\n"
   ],
   "id": "f9b47a00cf3ae597",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Additionally, we configure the last transformer block and the final LayerNorm module,\n",
    "which connects this block to the output layer, to be trainable\n",
    "    \n",
    "</div>"
   ],
   "id": "91f4c7e9ca95e60c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:54:53.496718Z",
     "start_time": "2025-08-26T11:54:53.483160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for params_1 in model_1.trf_blocks[-1].parameters():\n",
    "    params_1.requires_grad = True\n",
    "\n",
    "for params_1 in model_1.final_norm.parameters():\n",
    "    params_1.requires_grad = True\n",
    "    \n",
    "for params_2 in model_2.trf_blocks[-1].parameters():\n",
    "    params_2.requires_grad = True\n",
    "\n",
    "for params_2 in model_2.final_norm.parameters():\n",
    "    params_2.requires_grad = True"
   ],
   "id": "191bbc035b5603c1",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loss & Accuracy",
   "id": "9f24ec8988caf093"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:54:53.538641Z",
     "start_time": "2025-08-26T11:54:53.525886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# inputs = tokenizer.encode(\"Do you have time\")\n",
    "# inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "# print(\"Inputs:\", inputs)\n",
    "# print(\"Inputs dimensions:\", inputs.shape)"
   ],
   "id": "daf58803018982e",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:54:54.629426Z",
     "start_time": "2025-08-26T11:54:54.617441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# with torch.no_grad():\n",
    "#     outputs_1 = model_1(inputs)\n",
    "#     outputs_2 = model_2(inputs)\n",
    "# \n",
    "# print(\"Outputs of model 1:\\n\", outputs_1)\n",
    "# print(\"Outputs dimensions of model 1:\", outputs_1.shape)\n",
    "# \n",
    "# print(\"Outputs of model 2:\\n\", outputs_2)\n",
    "# print(\"Outputs dimensions of model 2:\", outputs_2.shape)"
   ],
   "id": "960c00660ee09988",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:54:54.696493Z",
     "start_time": "2025-08-26T11:54:54.683858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# probas_1 = torch.softmax(outputs_1[:, -1, :], dim=-1)\n",
    "# label_1 = torch.argmax(probas_1)\n",
    "# print(\"Class label:\", label_1.item())\n",
    "# \n",
    "# probas_2 = torch.softmax(outputs_2[:, -1, :], dim=-1)\n",
    "# label_2 = torch.argmax(probas_2)\n",
    "# print(\"Class label:\", label_2.item())"
   ],
   "id": "7365a9ea70607411",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:54:54.709138Z",
     "start_time": "2025-08-26T11:54:54.700518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# logits_1 = outputs_1[:, -1, :]\n",
    "# label_1 = torch.argmax(logits_1)\n",
    "# print(\"Class label:\", label_1.item())\n",
    "# \n",
    "# logits_2 = outputs_2[:, -1, :]\n",
    "# label_2 = torch.argmax(logits_2)\n",
    "# print(\"Class label:\", label_2.item())"
   ],
   "id": "4716eaa9ccdad26c",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:55:00.919048Z",
     "start_time": "2025-08-26T11:54:54.734696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model_1.to(device)\n",
    "model_2.to(device)\n",
    "\n",
    "torch.manual_seed(123)"
   ],
   "id": "a8b189a2cb061026",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23ec60b2b30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:55:01.340986Z",
     "start_time": "2025-08-26T11:55:01.332466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ],
   "id": "93a71c154d05a52f",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Accuracy",
   "id": "8b74c863b73fef76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:58:56.062503Z",
     "start_time": "2025-08-26T11:58:30.965711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_accuracy_1 = calc_accuracy_loader(train_loader, model_1, device, num_batches=10)\n",
    "val_accuracy_1 = calc_accuracy_loader(val_loader, model_1, device, num_batches=10)\n",
    "test_accuracy_1 = calc_accuracy_loader(test_loader, model_1, device, num_batches=10)\n",
    "print(f'Model_1\\nTrain accuracy: {train_accuracy_1}\\nTest accuracy: {test_accuracy_1}\\nValidation accuracy: {val_accuracy_1}')\n",
    "# \n",
    "# train_accuracy_2 = calc_accuracy_loader(train_loader, model_2, device, num_batches=10)\n",
    "# val_accuracy_2 = calc_accuracy_loader(val_loader, model_2, device, num_batches=10)\n",
    "# test_accuracy_2 = calc_accuracy_loader(test_loader, model_2, device, num_batches=10)\n",
    "# print(f'Model_2\\nTrain Accuracy: {train_accuracy_2}\\nTest Accuracy: {test_accuracy_2}\\nValidation Accuracy: {val_accuracy_2}')"
   ],
   "id": "a28a396e09d034a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.4875\n",
      "Validation accuracy: 0.45\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Loss",
   "id": "807be7529d8c4d7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T11:58:56.087910Z",
     "start_time": "2025-08-26T11:58:56.075325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ],
   "id": "8c6b509cdc4630fe",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:04:47.354602Z",
     "start_time": "2025-08-26T11:58:56.161425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss_1 = calc_loss_loader(train_loader, model_1, device, num_batches=5)\n",
    "    val_loss_1 = calc_loss_loader(val_loader, model_1, device, num_batches=5)\n",
    "    test_loss_1 = calc_loss_loader(test_loader, model_1, device, num_batches=5)\n",
    "    \n",
    "    train_loss_2 = calc_loss_loader(train_loader, model_2, device, num_batches=5)\n",
    "    val_loss_2 = calc_loss_loader(val_loader, model_2, device, num_batches=5)\n",
    "    test_loss_2= calc_loss_loader(test_loader, model_2, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss_1:.3f}\")\n",
    "print(f\"Validation loss: {val_loss_1:.3f}\")\n",
    "print(f\"Test loss: {test_loss_1:.3f}\")\n",
    "print('*'*10)\n",
    "print(f\"Training loss: {train_loss_2:.3f}\")\n",
    "print(f\"Validation loss: {val_loss_2:.3f}\")\n",
    "print(f\"Test loss: {test_loss_2:.3f}\")"
   ],
   "id": "ac12e3e98fc4aadd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.542\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n",
      "**********\n",
      "Training loss: 0.754\n",
      "Validation loss: 0.714\n",
      "Test loss: 0.683\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fine Tuning\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Step 1: Set model to training mode\n",
    "\n",
    "Step 2: Reset loss gradients from previous batch iteration\n",
    "\n",
    "Step 3: Calculate loss gradients\n",
    "\n",
    "Step 4: Update model weights using loss gradients\n",
    "\n",
    "Step 5: New: track examples instead of tokens\n",
    "\n",
    "Step 6: Optional evaluation step\n",
    "\n",
    "Step 7: Calculate accuracy after each epoch\n",
    "\n",
    "</div>"
   ],
   "id": "c43d0a04a6930ce1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:04:47.384839Z",
     "start_time": "2025-08-26T12:04:47.370297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ],
   "id": "a2f97367b1cfbb74",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:04:47.456874Z",
     "start_time": "2025-08-26T12:04:47.440233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ],
   "id": "9353862d8ca148ae",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:24:59.491292Z",
     "start_time": "2025-08-26T12:04:47.498375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_1.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model_1, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed of Model 1 in {execution_time_minutes:.2f} minutes.\")"
   ],
   "id": "bf1b82fff7cf2e54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed of Model 1 in 20.20 minutes.\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:24:59.549426Z",
     "start_time": "2025-08-26T12:24:59.532901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# start_time = time.time()\n",
    "# \n",
    "# torch.manual_seed(123)\n",
    "# \n",
    "# optimizer_2 = torch.optim.AdamW(model_1.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "# \n",
    "# num_epochs = 5\n",
    "# train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "#     model_2, train_loader, val_loader, optimizer, device,\n",
    "#     num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    "# )\n",
    "# \n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed of Model 2 in {execution_time_minutes:.2f} minutes.\")"
   ],
   "id": "a6555b2926dcef9a",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Step 1: Prepare inputs to the model\n",
    "\n",
    "Step 2: Truncate sequences if they too long\n",
    "    \n",
    "Step 3: Pad sequences to the longest sequence\n",
    "\n",
    "Step 4: Add batch dimension\n",
    "\n",
    "Step 5: Model inference without gradient tracking\n",
    "    \n",
    "Step 6: Logits of the last output token\n",
    "\n",
    "Step 7: Return the classified result\n",
    "\n",
    "</div>"
   ],
   "id": "7463946c6f615bd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:24:59.619545Z",
     "start_time": "2025-08-26T12:24:59.602911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ],
   "id": "b58fb522c99c61c5",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:24:59.711437Z",
     "start_time": "2025-08-26T12:24:59.661253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model_1, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ],
   "id": "9311cf72a6938903",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:27:21.549855Z",
     "start_time": "2025-08-26T12:27:19.283581Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model_1.state_dict(), \"review_classifier.pth\")",
   "id": "9b758ec9c66a095c",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:27:41.282368Z",
     "start_time": "2025-08-26T12:27:40.137995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model_1.load_state_dict(model_state_dict)"
   ],
   "id": "693e95d370b7442d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_18800\\3436285166.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"review_classifier.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d0113fb3b4c7a7ac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
